version: "1.0"

pipeline:
  name: "sales-data-pipeline"
  description: "Pipeline de procesamiento de datos de ventas"
  author: "Estudiante Lab 08"
  created_date: "2025-01-30"

validation:
  schema_path: "data/schemas/sales_schema_v1.json"
  required_files:
    - "sales_data.csv"
    - "product_catalog.csv"
  data_sources:
    api_endpoint: "https://api.ejemplo.com/ventas"
    database_connection: "postgresql://user:pass@localhost:5432/ventas_db"

processing:
  output_path: "data/processed/"
  steps:
    - "clean_duplicates"
    - "handle_missing_values"
    - "standardize_formats"
    - "calculate_totals"
    - "apply_business_rules"
  file_formats:
    input: ["csv", "json"]
    output: ["parquet", "csv"]

enrichment:
  catalog_path: "data/reference/product_catalog.csv"
  lookup_tables:
    - "region_mapping"
    - "product_categories"
    - "customer_segments"
  enrichment_strategies:
    - "product_catalog_join"
    - "geographic_enrichment"
    - "temporal_analysis"

quality:
  checks:
    - "completeness_threshold: 0.95"
    - "freshness_max_hours: 24"
    - "row_count_variation: 0.1"
    - "data_type_consistency: true"
    - "value_range_validation: true"
  thresholds:
    critical: 0.99
    warning: 0.95
    minor: 0.90

notifications:
  on_success: true
  on_failure: true
  on_warning: true
  channels:
    - "log_file"
    - "console"
  alert_levels:
    - "CRITICAL"
    - "ERROR"
    - "WARNING"

execution:
  max_retries: 3
  retry_delay: 30
  timeout_minutes: 60
  parallel_processing: false